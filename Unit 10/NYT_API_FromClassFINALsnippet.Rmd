---
title: "NY Times Data"
author: "Chad Madding"
date: "November 9, 2018"
output: html_document
---

### Sample R Code for Dealing with the NYT API
  
```{r lib and API}
library(dplyr)
library(tidyr)
library(plyr)
library(RTextTools)
library(jsonlite)
library(ggplot2)
library(caTools)
require(quanteda)#natural language processing package
require(RColorBrewer)

NYTIMES_KEY = "2f797325c5fc4d00aee61d2ae3e615d1";

# Let's set some parameters
term <- "central+park+jogger" # Need to use + to string together separate words
begin_date <- "19890101"
end_date <- "19991231"

baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
                  "&begin_date=",begin_date,"&end_date=",end_date,
                  "&facet_filter=true&api-key=",NYTIMES_KEY, sep="")

initialQuery <- jsonlite::fromJSON(baseurl)
#create the number of pages to search through
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)

#pulls down all the data from the above settings. Uses maxPages to know when to stop
pages <- list()
for(i in 0:maxPages){
  nytSearch <- jsonlite::fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame() 
  message("Retrieving page ", i)
  pages[[i+1]] <- nytSearch 
  Sys.sleep(1) 
}

allNYTSearch <- rbind_pages(pages)

# Visualize coverage by section
allNYTSearch %>% 
  group_by(response.docs.type_of_material) %>%
  dplyr::summarize(count=n()) %>%
  mutate(percent = (count / sum(count))*100) %>%
  ggplot() +
  geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()

#Make another column of News versus Other ... The labels

allNYTSearch$NewsOrOther = ifelse(allNYTSearch$response.docs.type_of_material == "News","News","Other")

#This function returns P(News | Keyword) 
#P(News|KW) = P(KW|News)* P(News) / P(KW)
Pnews_word = function(key_word = "jogging", trainingSet)
{
  print(key_word)
  NewsGroup = trainingSet[trainingSet$NewsOrOther == "News",]
  OtherGroup = trainingSet[trainingSet$NewsOrOther == "Other",]
  
  pNews = dim(NewsGroup)[1] / (dim(NewsGroup)[1] + dim(OtherGroup)[1])
  pOther = 1 - pNews
  
  pKWGivenNews = length(grep(paste("\\b",key_word,"\\b",sep=""),NewsGroup$response.docs.snippet,ignore.case = TRUE))/dim(NewsGroup)[1]
  pKWGivenOther = length(grep(paste("\\b",key_word,"\\b",sep=""),OtherGroup$response.docs.snippet,ignore.case = TRUE))/dim(OtherGroup)[1]
  
  pKW = length(grep(paste("\\b",key_word,"\\b",sep=""),trainingSet$response.docs.snippet,ignore.case = TRUE))/dim(trainingSet)[1]
  
  pNewsGivenKW = pKWGivenNews*pNews/pKW
  pOtherGivenKW = pKWGivenOther*pOther/pKW
  
  return(pNewsGivenKW)
}

theScoreHolderNews = c()
theScoreHolderOthers = c()
articleScoreNews = 0;
articleScoreOther = 0;


for (i in 1 : dim(allNYTSearch)[1])  #This loop iterates over the articles
{
  
  articleScoreNews = 0; 
  articleScoreOther = 0;
  #strsplit(gsub("[^[:alnum:] ]", "", str), " +")
  #strsplit(allNYTSearch$response.docs.snippet[i],split = " ")
   theText = unlist(strsplit(gsub("[^[:alnum:] ]", "", allNYTSearch$response.docs.snippet[i]), " +"))
  for(j in 1 : length(theText))  #This loop iterates over the headline (each word)
  {
    articleScoreNews = articleScoreNews + Pnews_word(theText[j],allNYTSearch)
    articleScoreOther = articleScoreOther + (1 - Pnews_word(theText[j],allNYTSearch))
  }
  theScoreHolderNews[i] = articleScoreNews
  theScoreHolderOther[i] = articleScoreOther
}

# Classify the aricle as News or Other based on a given piece of information from the article.
allNYTSearch$Classified = ifelse(theScoreHolderNews > theScoreHolderOther,"News","Other")
```


```{r NYT training and test set, echo=TRUE}
#create a NYT training and test set
set.seed(7) # Set Seed so that same sample can be reproduced in future also
split = sample.split(allNYTSearch$NewsOrOther, SplitRatio = .5)
TrainingNYT = subset(allNYTSearch, split == TRUE)
TestNYT = subset(allNYTSearch, split == FALSE)
#A head of the TrainingTX data
head(TrainingNYT)
#A head of the TestTX data
head(TestNYT)

nb.classifierNYT<-quanteda::textmodel_NB(TrainingNYT$NewsOrOther,TrainingNYT$Classified)
nb.classifierNYT

#Confusion Matrix on TestNYT
table(TestNYT$NewsOrOther,TestNYT$Classified)
```