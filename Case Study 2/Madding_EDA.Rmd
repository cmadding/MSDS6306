---
title: "Case Study 2 EDA only"
author: "Jackson Au & Chad Madding"
date: "November 27, 2018"
output:
 html_document:
   keep_md: yes
 pdf_document: default
 word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Install if the package doesn't exist 
#install.packages('DataExplorer') 
library(DataExplorer)
library(readr)
library(ggplot2)
```

    MSDS 6306: Doing Data Science
    Case Study 02
    Due: Sunday, December 9th at 11:59pm. 

#### Description:
DDSAnalytics is an analytics company that specializes in talent management solutions for Fortune 1000 companies. Talent management is defined as the iterative process of developing and retaining employees. It may include workforce planning, employee training programs, identifying high-potential employees and reducing/preventing voluntary employee turnover (attrition). To gain a competitive edge over its competition, DDSAnalytics is planning to leverage data science for talent management. The executive leadership has identified predicting employee turnover as its first application of data science for talent management. Before the business green lights the project, they have tasked your data science team to conduct an analysis of existing employee data.

```{r read in data, echo=TRUE}
#read in data
training_attrition <- read.csv("CaseStudy2-data.csv", header=T,na.strings=c(""))
validation_attrition <- read.csv("CaseStudy2Validation.csv", header=T,na.strings=c(""))

#data prep and cleaning
#check training_attrition for NAs
sapply(training_attrition,function(x) sum(is.na(x)))
#check validation_attrition for NAs
sapply(validation_attrition,function(x) sum(is.na(x)))

#we can drop ID, EmployeeCount, EmployeeNumber, Over18, StandardHours
training_attrition <- subset(training_attrition,select=c(2,3,4,5,6,7,8,9,12,13,14,15,16,17,18,19,20,21,22,24,25,26,27,29,30,31,32,33,34,35,36,37))
#droping the same from the validation set as well
validation_attrition <- subset(validation_attrition,select=c(2,3,4,5,6,7,8,9,12,13,14,15,16,17,18,19,20,21,22,24,25,26,27,29,30,31,32,33,34,35,36,37))
```

#### Goal:
Conduct exploratory data analysis (EDA) to determine factors that lead to attrition.

```{r exploratory data analysis, echo=TRUE}

#Variables
#looking at the structure of the data
str(training_attrition)

#the dimensions of the data
dim(training_attrition)

#looking at the distrubation of the data
#Continuous Variables
plot_histogram(training_attrition)
plot_density(training_attrition)

#Looking at the Categorical Variables
#Categorical Variables-Barplots
plot_bar(training_attrition)
```

####We will now start looking for the correlations in the data.
```{r looking for the correlations in the data, echo=TRUE}
#setting up the data for the correlations graph
numeric_training_attrition <- training_attrition[,c(1,4,6,7,9,11,13,15,17,19,21:32)]
numeric_Attrition = as.numeric(training_attrition$Attrition)- 1
numeric_training_attrition = cbind(numeric_Attrition, numeric_training_attrition)

#looking at the structure of the data
str(numeric_training_attrition)

#looking at the correlations in the data
library(corrplot)
M <- cor(numeric_training_attrition)
corrplot(M, method="circle")
```
####Next we will find out how many correlations are bigger than 0.70.

```{r correlations bigger than 0.70, echo=TRUE}
#Finding how many correlations are bigger than 0.70
k = 0
for(i in 1:23){
for(r in 1:23){
  if(M[i,r]> 0.70 & i != r){
    k= k + 1
  }
}  }
print(k/2)
```

#####Lets break down those top 7.
```{r break down those top 7, echo=TRUE}
#looking at the top 7 over 0.70

# Overtime vs Attiriton
l <- ggplot(training_attrition, aes(OverTime,fill = Attrition))
l <- l + geom_histogram(stat="count")
print(l)
tapply(as.numeric(training_attrition$Attrition) - 1 ,training_attrition$OverTime,mean)
```
This chart shows that people who work over time have more Attrition.

```{r MaritalStatus,echo=TRUE}
### MaritalStatus vs Attiriton
l <- ggplot(training_attrition, aes(MaritalStatus,fill = Attrition))
l <- l + geom_histogram(stat="count")
print(l)
tapply(as.numeric(training_attrition$Attrition) - 1 ,training_attrition$MaritalStatus,mean)
```
Single people have more tendency to be subject to attrition.

```{r JobRole, echo=TRUE}
###JobRole vs Attrition
l <- ggplot(training_attrition, aes(JobRole,fill = Attrition))
l <- l + geom_histogram(stat="count") +
  theme(axis.text.x=element_text(angle=45,hjust=1))
print(l)
tapply(as.numeric(training_attrition$Attrition) - 1 ,training_attrition$JobRole,mean)
mean(as.numeric(training_attrition$Attrition) - 1)
```
Here we can see that laboratory technician, human resource workers and sales representative roles have more attrition.

```{r}
###Gender vs Attrition
l <- ggplot(training_attrition, aes(Gender,fill = Attrition))
l <- l + geom_histogram(stat="count")
print(l)
tapply(as.numeric(training_attrition$Attrition) - 1 ,training_attrition$Gender,mean)
```
Gender doesn't seem to play much of a role in attrition.

```{r}
###EducationField vs Attrition
l <- ggplot(training_attrition, aes(EducationField,fill = Attrition))
l <- l + geom_histogram(stat="count") +
  theme(axis.text.x=element_text(angle=45,hjust=1))
print(l)
tapply(as.numeric(training_attrition$Attrition) - 1 ,training_attrition$EducationField,mean)

```
Workers holding degrees in Technological and Human Resources are outstanding with a high attrition ratio.

```{r}
###Department vs Attrition
l <- ggplot(training_attrition, aes(Department,fill = Attrition))
l <- l + geom_histogram(stat="count")
print(l)
tapply(as.numeric(training_attrition$Attrition) - 1 ,training_attrition$Department,mean)
```
Department results are showing that Research & Development have a slightley higher probability of attrition.

```{r}
###BusinessTravel vs Attrition
l <- ggplot(training_attrition, aes(BusinessTravel,fill = Attrition))
l <- l + geom_histogram(stat="count")
print(l)
tapply(as.numeric(training_attrition$Attrition) - 1 ,training_attrition$BusinessTravel,mean)
```
Looking at travel verses non travel we see that persons traveling more frequently have a higher probability of attrition.

```{r Overtime, echo=TRUE}
### x=Overtime, y= Age, z = MaritalStatus , t = Attrition
ggplot(training_attrition, aes(OverTime, Age)) +  
  facet_grid(.~MaritalStatus) +
  geom_jitter(aes(color = Attrition),alpha = 0.4) +  
  ggtitle("x=Overtime, y= Age, z = MaritalStatus , t = Attrition") +  
  theme_light()
```
This graph shows that single people under 35, working overtime are subject to attrition.

```{r}
### MonthlyIncome vs. Age, by  color = Attrition
ggplot(training_attrition, aes(MonthlyIncome, Age, color = Attrition)) + 
  geom_jitter() +
  ggtitle("MonthlyIncome vs. Age, by  color = Attrition ") +
  theme_light()
```
This last graph shows a bit of logical information. As Age increases, Monthly Income tends to increase as well.

####There are a few other things in the data:
1. The most outstanding result is between Job Level and Monthly income, whose correlation is 0.95.
2. A higher performance rating shows a more Percent salary hike, whose correlation is 0.772.
3. The more years wotking for the company, the higher Job Levels, whose correlation is 0.77.
4. The more total years working for the company, the higher their monthly income, whose correlation is 0.77.
5. The more years with their current manager, the more years they were at the company, whose correlation is 0.763.
6. The last two show more logical triends. The more years at company, the more years they are in their current role, whose correlation is 0.753.
7. Last, the more years with current manager, the more years in their current role, whose correlation is 0.71.

###Predictions with logistic regression
```{r Predictions with logistic regression, echo=TRUE}
#loading the needed liraries
library(caTools)
library(e1071)
library(glmnet)
#setting up both the training and validation data
training_attrition_mydatanew = training_attrition[,-c(6,9,22)]
validation_attrition_mydatanew = validation_attrition[,-c(6,9,22)]

#looking at the structure of both data sets
str(training_attrition_mydatanew)
str(validation_attrition_mydatanew)

#simplifining the names
train <- training_attrition_mydatanew
test <- validation_attrition_mydatanew

#using glm to train the full model with a binomial setting
model_glm_binomial <- glm(Attrition ~ ., data = train, family='binomial')
#running the test data through the model
predicted_glm_binomial <- predict(model_glm_binomial, test, type='response')
predicted_glm_binomial <- ifelse(predicted_glm_binomial > 0.5,1,0)
summary(model_glm_binomial)

#using glm to train the full model with a logit setting
model_glm_logit <- glm(Attrition ~.,family=binomial(link='logit'),data=train)
#running the test data through the model
predicted_glm_logit <- predict(model_glm_logit, test, type='response')
predicted_glm_logit <- ifelse(predicted_glm_logit > 0.5,1,0)
summary(model_glm_logit)

table(test$Attrition, predicted_glm_binomial)
#Checking the prediction accuracy
print((240+13)/300)

table(test$Attrition, predicted_glm_logit)
#Checking the prediction accuracy
print((240+13)/300)

#adding the predictions back into the data
validation_attrition$PredictedAttrition_binomial <- predicted_glm_binomial
validation_attrition$PredictedAttrition_logit <- predicted_glm_logit

#check out the predicted data
validation_attrition_compair <- validation_attrition[,c(2,33:34)]
```
The prediction accuracy of logistic regression using binomial is about 0.84.
The prediction accuracy of logistic regression using logit is about 0.84.
